bundle:
  name: routing-optimization

variables:
  environment:
    description: "Deployment environment (dev, staging, prod)"
    default: dev

targets:
  dev:
    default: true
    mode: development

resources:
  jobs:
    demo_workflow:
      name: "Routing Optimization"

      job_clusters:
        - job_cluster_key: osrm_build
          new_cluster:
            spark_version: "16.4.x-cpu-ml-scala2.12"
            num_workers: 0          # single driver
            node_type_id: m5d.4xlarge # or Standard_D4ds_v5 on Azure
            spark_conf:
              "spark.databricks.cluster.profile": "singleNode"
              "spark.master": "local[*]"
            custom_tags:
              ResourceClass: SingleNode
        - job_cluster_key: solver_cluster
          new_cluster:
            spark_version: "16.4.x-cpu-ml-scala2.12"
            node_type_id: m5d.4xlarge
            num_workers: 4
            spark_conf:
              "spark.databricks.pyspark.dataFrameChunk.enabled": "true"
              "spark.task.resource.gpu.amount": "0"
            init_scripts:
              - workspace:
                  destination: "/Users/josh.melton@databricks.com/routing/osrm-backend.sh"

      tasks:
        - task_key: build_osrm_map
          job_cluster_key: osrm_build
          notebook_task:
            notebook_path: "01_osrm_server_setup.py"

        - task_key: route_optimisation
          depends_on:
           - task_key: build_osrm_map
          job_cluster_key: solver_cluster
          notebook_task:
            notebook_path: "03_route_optimization.py"
