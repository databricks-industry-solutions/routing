{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afbbca13-e716-4d60-a616-5f1a6a6ecedc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install Libraries"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%pip install osmnx==2.0.4 protobuf==6.31.1 ortools==9.14.6206 folium==0.20.0\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3d2f593-ad3b-48e4-84a8-c3e73055a9e1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set Configs"
    }
   },
   "outputs": [],
   "source": [
    "NUM_SHIPMENTS = 40_000\n",
    "num_routes = 320  # total trucks available\n",
    "MAX_EV = 4000\n",
    "MAX_VAN = 8000\n",
    "DEPOT_LAT, DEPOT_LON = 39.7685, -86.1580 # start and end point for each route\n",
    "SOLVER_THINKING_TIME = 1 # how long should the solver spend on each route\n",
    "\n",
    "\n",
    "catalog = \"josh_melton\"\n",
    "schema = \"routing\"\n",
    "shipments_table = f\"{catalog}.{schema}.raw_shipments\"\n",
    "clustered_table = f\"{catalog}.{schema}.shipments_by_route\"\n",
    "optimal_routes_table = f\"{catalog}.{schema}.optimized_routes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18f0088b-8036-48f1-8726-d423129dfd59",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Imports"
    }
   },
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n",
    "from ortools.constraint_solver import pywrapcp, routing_enums_pb2, routing_parameters_pb2\n",
    "from ortools.util import optional_boolean_pb2 as ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1701572-7b6b-46cd-bd62-9122028d2efb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read Shipment Data"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    shipments_df = spark.read.table(shipments_table) \n",
    "except Exception:\n",
    "    # to see how this was generated, or generate different data yourself, check utils/data_generation.py\n",
    "    shipments_df = spark.read.csv(\"utils/shipments.csv\") \n",
    "    shipments_df.write.mode(\"overwrite\").saveAsTable(shipments_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92039c39-6da5-47f1-86ca-6cf4cb736058",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cluster Shipments"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Helper: two-way median split for overweight routes\n",
    "def median_bisect(sdf, cid, max_weight):\n",
    "    # choose the axis with larger spread\n",
    "    bounds = (sdf.agg(F.max(\"latitude\").alias(\"lat_max\"),\n",
    "                      F.min(\"latitude\").alias(\"lat_min\"),\n",
    "                      F.max(\"longitude\").alias(\"lon_max\"),\n",
    "                      F.min(\"longitude\").alias(\"lon_min\"))\n",
    "                  .collect()[0])\n",
    "    lat_range = bounds.lat_max - bounds.lat_min\n",
    "    lon_range = bounds.lon_max - bounds.lon_min\n",
    "    axis      = \"latitude\" if lat_range >= lon_range else \"longitude\"\n",
    "\n",
    "    # median along that axis (1-% error is fine)\n",
    "    median = sdf.approxQuantile(axis, [0.5], 0.01)[0]\n",
    "\n",
    "    # assign sub-cluster ids\n",
    "    split_df = sdf.withColumn(\"cluster_id\",\n",
    "        F.when(F.col(axis) <= median, F.lit(f\"{cid}-1\"))\n",
    "         .otherwise(                F.lit(f\"{cid}-2\"))\n",
    "    )\n",
    "    return split_df\n",
    "\n",
    "# 2. Main builder\n",
    "def build_clusters(shipments_df, num_routes, max_weight=MAX_VAN):\n",
    "    # 2.1 initial spatial k-means\n",
    "    vec = VectorAssembler(inputCols=[\"latitude\", \"longitude\"],\n",
    "                          outputCol=\"features\").transform(shipments_df)\n",
    "\n",
    "    base_model = KMeans(k=num_routes, seed=1).fit(vec.select(\"features\"))\n",
    "    clustered  = (\n",
    "        base_model.transform(vec)\n",
    "                  .withColumnRenamed(\"prediction\", \"cluster_id\")\n",
    "                  .drop(\"features\")                    # no vector in final table\n",
    "    )\n",
    "\n",
    "    # 2.2 overweight cluster ids\n",
    "    heavy_ids = (\n",
    "        clustered.groupBy(\"cluster_id\")\n",
    "                 .agg(F.sum(\"weight\").alias(\"total_wt\"))\n",
    "                 .filter(F.col(\"total_wt\") > max_weight)\n",
    "                 .select(\"cluster_id\")\n",
    "                 .distinct()\n",
    "                 .collect()\n",
    "    )\n",
    "    heavy_ids = [row[\"cluster_id\"] for row in heavy_ids]\n",
    "    print(\"Over-capacity clusters â†’\", heavy_ids or \"none ðŸŽ‰\")\n",
    "\n",
    "    from functools import reduce\n",
    "\n",
    "    # 2.3 bisect each heavy cluster\n",
    "    if heavy_ids:\n",
    "        heavy_df = clustered.filter(F.col(\"cluster_id\").isin(heavy_ids))\n",
    "        keep_df  = clustered.filter(~F.col(\"cluster_id\").isin(heavy_ids))\n",
    "\n",
    "        # create one DataFrame per overweight cluster\n",
    "        splits = [\n",
    "            median_bisect(\n",
    "                heavy_df.filter(F.col(\"cluster_id\") == cid), cid, max_weight\n",
    "            )\n",
    "            for cid in heavy_ids\n",
    "        ]\n",
    "\n",
    "        # fold the list into a single DF: split_df = splits[0] âˆª splits[1] âˆª â€¦\n",
    "        split_df = reduce(lambda d1, d2: d1.unionByName(d2), splits)\n",
    "\n",
    "        # final merged result\n",
    "        clustered = keep_df.unionByName(split_df)\n",
    "\n",
    "    # 2.4 cast id â†’ string, save & return\n",
    "    return clustered.withColumn(\"cluster_id\", F.col(\"cluster_id\").cast(\"string\"))\n",
    "\n",
    "# 3. Run, save, and sanity check\n",
    "try :\n",
    "    clustered_df = spark.read.table(clustered_table)\n",
    "except Exception:\n",
    "    clustered_df = build_clusters(\n",
    "        shipments_df,\n",
    "        num_routes=num_routes, \n",
    "        max_weight=MAX_VAN,\n",
    "    )\n",
    "    clustered_df.write.mode(\"overwrite\").saveAsTable(clustered_table)\n",
    "\n",
    "    (\n",
    "        clustered_df.groupBy(\"cluster_id\")\n",
    "        .agg(F.count(\"*\").alias(\"num_deliveries\"),\n",
    "            F.sum(\"weight\").alias(\"total_weight\"))\n",
    "        .orderBy(F.col(\"total_weight\").desc())\n",
    "    ).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "569759d8-bca8-499d-92f2-2c5300fa8640",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define Route Optimizer"
    }
   },
   "outputs": [],
   "source": [
    "def solve_cluster(pdf: pd.DataFrame) -> pd.DataFrame:\n",
    "    # -------- 1. Build coordinate list -------------------------------------\n",
    "    coords = [(DEPOT_LON, DEPOT_LAT)] + list(zip(pdf[\"longitude\"], pdf[\"latitude\"]))\n",
    "    n      = len(coords)\n",
    "\n",
    "    # -------- 2. Trivial cases ---------------------------------------------\n",
    "    if n == 1:      # depot only  â†’ no route rows\n",
    "        return pd.DataFrame([], columns=[\n",
    "            \"cluster_id\",\"truck_type\",\"route_index\",\n",
    "            \"package_id\",\"latitude\",\"longitude\"\n",
    "        ])\n",
    "\n",
    "    if n == 2:      # depot + one stop\n",
    "        r = pdf.iloc[0]\n",
    "        return pd.DataFrame([{\n",
    "            \"cluster_id\":  str(r[\"cluster_id\"]),\n",
    "            \"truck_type\":  \"EV\" if r[\"weight\"] <= MAX_EV else \"Van\",\n",
    "            \"route_index\": 0,\n",
    "            \"package_id\":  r[\"package_id\"],\n",
    "            \"latitude\":    r[\"latitude\"],\n",
    "            \"longitude\":   r[\"longitude\"],\n",
    "        }])\n",
    "\n",
    "    # -------- 3. Single OSRM /table call -----------------------------------\n",
    "    coord_str = \";\".join(f\"{lon:.6f},{lat:.6f}\" for lon, lat in coords)\n",
    "\n",
    "    def osrm_table(radius=None):\n",
    "        extra = \"\"\n",
    "        if radius is not None:                         # optional wider snap\n",
    "            radii = \";\".join([str(radius)] * n)\n",
    "            extra = f\"&radiuses={radii}\"\n",
    "        url = (\n",
    "            f\"http://localhost:5100/table/v1/driving/{coord_str}\"\n",
    "            f\"?annotations=duration{extra}\"\n",
    "        )\n",
    "        return requests.get(url, timeout=20).json()\n",
    "\n",
    "    data = osrm_table()          # first try (server default radius 100 m)\n",
    "    if data.get(\"code\") != \"Ok\":\n",
    "        data = osrm_table(radius=400)  # fallback for off-graph points\n",
    "\n",
    "    if data.get(\"code\") != \"Ok\" or \"durations\" not in data:\n",
    "        raise RuntimeError(f\"OSRM error: {data}\")\n",
    "\n",
    "    full_dur = (np.array(data[\"durations\"], dtype=float)).astype(int)\n",
    "\n",
    "    # -------- 4. OR-Tools model --------------------------------------------\n",
    "    demands  = [0] + pdf[\"weight\"].tolist()\n",
    "    capacity = MAX_VAN if sum(demands) > MAX_EV else MAX_EV\n",
    "\n",
    "    manager  = pywrapcp.RoutingIndexManager(n, 1, 0)\n",
    "    routing  = pywrapcp.RoutingModel(manager)\n",
    "\n",
    "    def cost_cb(i, j):\n",
    "        return full_dur[manager.IndexToNode(i)][manager.IndexToNode(j)]\n",
    "      \n",
    "    routing.SetArcCostEvaluatorOfAllVehicles(routing.RegisterTransitCallback(cost_cb))\n",
    "\n",
    "    demand_cb = routing.RegisterUnaryTransitCallback(\n",
    "        lambda idx: demands[manager.IndexToNode(idx)]\n",
    "    )\n",
    "    print(\"demands :\", demands)              # list delivered at each stop\n",
    "    print(\"total   :\", sum(demands))         # vehicle must deliver at least this\n",
    "    print(\"capacity:\", capacity)             # max vehicle load you allow\n",
    "    print(\"max indiv demand:\", max(demands))\n",
    "\n",
    "    # -------- 5. Search parameters ----------------------------------------\n",
    "    sp = pywrapcp.DefaultRoutingSearchParameters()\n",
    "    sp.first_solution_strategy    = routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC\n",
    "    sp.local_search_metaheuristic = routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH # try other heuristics\n",
    "    # sp.time_limit.seconds = min(30, n)\n",
    "    sp.solution_limit = n*10*SOLVER_THINKING_TIME\n",
    "    sp.guided_local_search_lambda_coefficient = 0.2\n",
    "    sp.log_search = True\n",
    "    # ops = sp.local_search_operators\n",
    "    # ops.use_full_path_lns  = ob.BOOL_TRUE\n",
    "    # ops.use_two_opt        = ob.BOOL_TRUE\n",
    "    # ops.use_or_opt         = ob.BOOL_TRUE\n",
    "    # ops.use_lin_kernighan  = ob.BOOL_TRUE   \n",
    "\n",
    "    # -------- 6. Solve & extract route -------------------------------------\n",
    "    sol = routing.SolveWithParameters(sp)\n",
    "    if sol is None:\n",
    "        raise RuntimeError(\"No solution found for cluster\")\n",
    "\n",
    "    idx, visit = routing.Start(0), []\n",
    "    while not routing.IsEnd(idx):\n",
    "        node = manager.IndexToNode(idx)\n",
    "        if node != 0:\n",
    "            visit.append(node - 1)\n",
    "        idx = sol.Value(routing.NextVar(idx))\n",
    "\n",
    "    visited_pdf = pdf.iloc[visit]\n",
    "    truck_type  = \"EV\" if capacity > MAX_EV else \"Van\"\n",
    "\n",
    "    rows = []\n",
    "    for i, (_, r) in enumerate(visited_pdf.iterrows()):\n",
    "        rows.append({\n",
    "            \"cluster_id\":  str(r[\"cluster_id\"]),\n",
    "            \"truck_type\":  truck_type,\n",
    "            \"route_index\": i,        \n",
    "            \"package_id\":  r[\"package_id\"],\n",
    "            \"latitude\":    r[\"latitude\"],\n",
    "            \"longitude\":   r[\"longitude\"],\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "286193dd-8ca3-4fb1-9bbb-c9b83977072c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Small Example"
    }
   },
   "outputs": [],
   "source": [
    "from utils.plotter import plot_route_folium\n",
    "\n",
    "small_example = [\n",
    "    # cluster_id, package_id, latitude,  longitude, weight\n",
    "    (1, \"N1\", 39.8184, -86.1581, 12.0),\n",
    "    (1, \"N2\", 39.8584, -86.2081,  8.5),\n",
    "    (1, \"S1\", 39.7184, -86.1581, 15.0),\n",
    "    (1, \"S2\", 39.6784, -86.1081,  6.0),\n",
    "    (1, \"S3\", 39.6584, -86.2081, 10.0),\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"cluster_id\",  StringType(), False),\n",
    "    StructField(\"package_id\",  StringType(),  False),\n",
    "    StructField(\"latitude\",    DoubleType(),  False),\n",
    "    StructField(\"longitude\",   DoubleType(),  False),\n",
    "    StructField(\"weight\",  DoubleType(),  False),\n",
    "])\n",
    "\n",
    "small_example_pdf = spark.createDataFrame(small_example, schema).toPandas()\n",
    "result_pdf = solve_cluster(small_example_pdf)\n",
    "plot_route_folium(result_pdf) # Remember the depot (not visualized) is technically the start and end of the route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "060ac41a-6e6d-4f23-8ed6-9e8a81f1c798",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "One Route Example"
    }
   },
   "outputs": [],
   "source": [
    "single_cluster_df = clustered_df.where(clustered_df.cluster_id == 1).toPandas()\n",
    "result_df = solve_cluster(single_cluster_df)\n",
    "plot_route_folium(result_df) # Remember the depot (not visualized) is technically the start and end of the route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da58cce8-5d55-4895-8de5-e00935e31ebe",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Optimize Every Route"
    }
   },
   "outputs": [],
   "source": [
    "# We use the applyInPandas API to run the solve_cluster function on each cluster (route) in parallel\n",
    "result_schema = \"cluster_id STRING, truck_type STRING, route_index INT, package_id STRING, latitude DOUBLE, longitude DOUBLE\"\n",
    "optimal_routes_df = clustered_df.groupBy(\"cluster_id\").applyInPandas(solve_cluster, schema=result_schema)\n",
    "optimal_routes_df.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(optimal_routes_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a659c7a9-2937-48e1-a540-c7741916d20c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The *route* and *table* methods of the OSRM Backend Server are two of several methods available through the server's REST API.  The full list of methods include:\n",
    "</p>\n",
    "\n",
    "* [route](http://project-osrm.org/docs/v5.5.1/api/#route-service) - finds the fastest route between coordinates in the supplied order\n",
    "* [nearest](http://project-osrm.org/docs/v5.5.1/api/#nearest-service) - snaps a coordinate to the street network and returns the nearest n matches\n",
    "* [table](http://project-osrm.org/docs/v5.5.1/api/#table-service) - computes the duration of the fastest route between all pairs of supplied coordinates\n",
    "* [match](http://project-osrm.org/docs/v5.5.1/api/#match-service) - snaps given GPS points to the road network in the most plausible way\n",
    "* [trip](http://project-osrm.org/docs/v5.5.1/api/#trip-service) - solves the Traveling Salesman Problem using a greedy heuristic (farthest-insertion algorithm)\n",
    "* [tile](http://project-osrm.org/docs/v5.5.1/api/#tile-service) - generates Mapbox Vector Tiles that can be viewed with a vector-tile capable slippy-map viewer\n",
    "\n",
    "To make any of these accessible during Spark dataframe processing, simply construct a pandas UDF around the HTTP REST API call as demonstrated above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af6c596e-6bea-4f36-b738-f8ab0098c501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "&copy; 2025 Databricks, Inc. All rights reserved. The source in this notebook is provided subject to the [Databricks License](https://databricks.com/db-license-source).  All included or referenced third party libraries are subject to the licenses set forth below.\n",
    "\n",
    "| library                                | description             | license    | source                                              |\n",
    "|----------------------------------------|-------------------------|------------|-----------------------------------------------------|\n",
    "| OSRM Backend Server                                  | High performance routing engine written in C++14 designed to run on OpenStreetMap data | BSD 2-Clause \"Simplified\" License    | https://github.com/Project-OSRM/osrm-backend                   |\n",
    "| osmnx        | Download, model, analyze, and visualize street networks and other geospatial features from OpenStreetMap in Python | MIT License            | https://github.com/gboeing/osmnx                    |\n",
    "| ortools      | Operations research tools developed at Google for combinatorial optimization | Apache License 2.0     | https://github.com/google/or-tools                   |\n",
    "| folium       | Visualize data in Python on interactive Leaflet.js maps                      | MIT License            | https://github.com/python-visualization/folium       |\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2804724653930863,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "03_route_optimization",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
